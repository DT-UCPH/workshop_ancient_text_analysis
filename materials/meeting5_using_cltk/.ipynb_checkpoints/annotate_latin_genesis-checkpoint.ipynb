{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK IS IN DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Introduction](#introduction)\n",
    "1. [Install pre-release of CLTK](#install)\n",
    "1. [Load data](#load)\n",
    "1. [Run NLP pipeline with `NLP()`](#run-nlp)\n",
    "1. [Inspect CLTK `Doc`](#inspect-doc)\n",
    "1. [Inspect CLTK `Word`](#inspect-word)\n",
    "1. [Modeling morphology with `MorphosyntacticFeature` and `MorphosyntacticFeatureBundle`](#morph)\n",
    "1. [Modeling syntax with `Form` and `DependencyTree`](#syntax)\n",
    "1. [Feature extraction](#features)\n",
    "1. [Brief demonstration of `NLP()` for Ancient Greek](#greek-nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "This notebook is based on [a notebook](https://github.com/cltk/cltk/blob/master/notebooks/CLTK%20Demonstration.ipynb) from the [Classical Language Toolkit project](http://cltk.org). We will annotate the text of the Vulgate of Genesis, using the pipeline that is provided for the Latin language. We use the text of the Latin Genesis as it is provided [here](https://github.com/cltk/lat_text_tesserae).\n",
    "\n",
    "This notebook demonstrates how to use `NLP()`, the CLTK's primary interface, in Latin and Ancient Greek. Pipelines are available for 17 languages (see [Languages](https://docs.cltk.org/en/latest/languages.html) in the docs).\n",
    "\n",
    "Full documentation available at <https://docs.cltk.org/en/latest/cltk.html#cltk.nlp.NLP>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install CLTK <a name=\"install\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requires Python 3.7, 3.8, or 3.9\n",
    "\n",
    "# !pip install cltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data <a name=\"load\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the text of Genesis, read it line by line, parse the label (book, chapter, verse), and store the data in the dictionary vulgate_genesis. In this dict, the keys are a tuple containing book, chapter and verse, and the values consist of a string, containing the text of a verse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vulgate_genesis = {}\n",
    "\n",
    "with open(\"jerome.vulgate.part.1.genesis.tess\") as gen:\n",
    "    for line in gen:\n",
    "\n",
    "        label, text = line.split('> ')\n",
    "        _, bo_ch_ve = label.split()\n",
    "        bo, ch, ve = bo_ch_ve.split('.')\n",
    "        vulgate_genesis[(bo, ch, ve)] = text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many verses are there in Genesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vulgate_genesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the text of Genesis 10:10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vulgate_genesis[('Genesis', '10', '10')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run NLP pipeline with `NLP()` <a name=\"run-nlp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk import NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cltk_nlp = NLP(language=\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing ``LatinLexiconProcess`` for this demo b/c it is slow (adds ~9 mins total)\n",
    "cltk_nlp.pipeline.processes.pop(-1)\n",
    "print(cltk_nlp.pipeline.processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the pipeline does with Genesis 1:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cltk_doc = cltk_nlp.analyze(text=vulgate_genesis[('Genesis', '1', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect CLTK `Doc` <a name=\"inspect-doc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline has created a Doc object of our string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(cltk_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we access this Doc object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x for x in dir(cltk_doc) if not x.startswith(\"__\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the tokens! Note that the semicolon at the end is parsed as a separate token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc.lemmata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_tokens is a list of lists, which contains the sentences in the string under consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc.sentences_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect CLTK `Word` <a name=\"inspect-word\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most powerful, though, is the ``Doc.words`` accessor, which is a list of ``Word`` objects. These ``Word`` objects contain all information that was generated during the NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Word object for each token\n",
    "print(len(cltk_doc.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can go token-by-token via ``Doc.words`` or via the intermediary step of looping through sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc.sentences_strings[0])\n",
    "sentence_gen_1_1 = cltk_doc.sentences[0]  # type: List[Word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sentence_gen_1_1:\n",
    "    print(word)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this word, you can see information for lexicography (`.lemmata`), semantics (`.embedding`), morphology (`.pos`, `.features`), syntax (`.governor`, `.dependency_relation`), plus other information most users would find helpful (`.stop`, `.named_entity`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling morphology with `MorphosyntacticFeature` and `MorphosyntacticFeatureBundle` <a name=\"morph\"></a>\n",
    "\n",
    "When a language's `Pipeline` builds each `Word` object, morphological information is stored at several accessors. Those of interest to most users are `.pos` and `.features`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the verb in the sentence: creavit, which is the third word, so it has index 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creav = sentence_gen_1_1[2]\n",
    "print('Word.string:', creav.string)\n",
    "print(\"\")\n",
    "\n",
    "print('Word.pos:', creav.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CLTK contains classes a specific class for [the annotation types defined by v2 of the Universal Dependencies project](https://universaldependencies.org/u/feat/all.html). In the CLTK's codebase, these are located at [cltk/morphology/universal_dependencies_features.py](https://github.com/cltk/cltk/blob/dev/src/cltk/morphology/universal_dependencies_features.py).\n",
    "\n",
    "For instance, a Latin verb requires a label for its [https://universaldependencies.org/u/feat/all.html#al-u-feat/Mood](mood) (e.g., indicative), which the UD project defines as \"a feature that expresses modality and subclassifies finite verb forms\".\n",
    "\n",
    "Though morphological taggers may annnotate a verb's mood variously (\"ind.\", \"indicative\", \"Indic\", etc.), the CLTK maps the term into the following, standardized `Mood`.\n",
    "\n",
    "``` python\n",
    "class Mood(MorphosyntacticFeature):\n",
    "    \"\"\"The mood of a verb.\n",
    "    see https://universaldependencies.org/u/feat/Mood.html\n",
    "    \"\"\"\n",
    "\n",
    "    admirative = auto()\n",
    "    conditional = auto()\n",
    "    desiderative = auto()\n",
    "    imperative = auto()\n",
    "    indicative = auto()\n",
    "    jussive = auto()\n",
    "    necessitative = auto()\n",
    "    optative = auto()\n",
    "    potential = auto()\n",
    "    purposive = auto()\n",
    "    quotative = auto()\n",
    "    subjunctive = auto()\n",
    "```\n",
    "\n",
    "Turning back to the the above example word, we can see such features at `.features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# type\n",
    "print(\"type(`Word.features`):\", type(creav.features))\n",
    "print(\"\")\n",
    "# str repr of `MorphosyntacticFeatureBundle`\n",
    "print(\"`Word.features`:\", creav.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user may inspect a `MorphosyntacticFeatureBundle` in a manner similar to a `dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mood:\", creav.features[\"Mood\"], creav.features[\"Mood\"][0].name)  # type: List[Mood]\n",
    "print(\"Number:\", creav.features[\"Number\"])  # type: List[Number]\n",
    "print(\"Person:\", creav.features[\"Person\"])  # type: List[Person]\n",
    "print(\"Tense:\", creav.features[\"Tense\"])  # type: List[Tense]\n",
    "print(\"VerbForm:\", creav.features[\"VerbForm\"])  # type: List[VerbForm]\n",
    "print(\"Voice:\", creav.features[\"Voice\"])  # type: List[Voice]\n",
    "\n",
    "# Note: The values returned here are a list, though under normally only one \n",
    "# morphological form will be available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking a bit closer at `MorphosyntacticFeature`, we can see how its data type inherits from the Python builtin [IntEnu](https://docs.python.org/3/library/enum.html#enum.IntEnum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mood_obj = a_word_concurrunt.features[\"Mood\"][0]\n",
    "# see type\n",
    "print(\"type(a_mood_obj):\", type(a_mood_obj))\n",
    "print(\"\")\n",
    "# See inheritance\n",
    "from enum import IntEnum\n",
    "print(\"Is `IntEnum`?\", isinstance(a_mood_obj, IntEnum))\n",
    "print(\"\")\n",
    "# \n",
    "from cltk.morphology.morphosyntax import MorphosyntacticFeature\n",
    "print(\"`Mood` inherits from `MorphosyntacticFeature`?\", isinstance(a_mood_obj, MorphosyntacticFeature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can manipulate this object as any IntEnum plus a few extras\n",
    "\n",
    "print(\"`MorphosyntacticFeature` accessors:\", [x for x in dir(a_mood_obj) if not x.startswith(\"__\")])\n",
    "print(\"\")\n",
    "print(\"MorphosyntacticFeature.name:\", a_mood_obj.name)  # type: str\n",
    "# A stable int value is available, too, associated with this name\n",
    "print(\"MorphosyntacticFeature.value:\", a_mood_obj.value)  # type: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can create their own `MorphosyntacticFeature` and `MorphosyntacticFeatureBundle`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.morphology.morphosyntax import MorphosyntacticFeatureBundle\n",
    "from cltk.morphology.universal_dependencies_features import Mood, Number, Person, VerbForm, Voice\n",
    "\n",
    "latin_word_sim = \"sim\"\n",
    "\n",
    "mood = Mood.subjunctive\n",
    "voice = Voice.active\n",
    "person = Person.first\n",
    "number = Number.singular\n",
    "verb_form = VerbForm.finite\n",
    "\n",
    "latin_word_sim_bundle = MorphosyntacticFeatureBundle(mood, voice, person, number, verb_form)\n",
    "print(latin_word_sim_bundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we may even construct a `Word` with this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.core.data_types import Word\n",
    "\n",
    "print(Word(string=\"sim\", features=latin_word_sim_bundle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more on this or any other CLTK class, use `help()`\n",
    "# help(a_mood_obj)\n",
    "# help(MorphosyntacticFeatureBundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Extra morphological info may be written in `str` type\n",
    "# to to the values at `.upos` and `.xpos` for languages using\n",
    "# Stanza project\n",
    "\n",
    "# Note: The particular annoations at these are often inconsistent across\n",
    "# languages or even treebanks within a single language; hence the benefit\n",
    "# of the CLTK's modeling at `.pos`.\n",
    "print(\"`Word.upos`:\", a_word_concurrunt.upos)\n",
    "print(\"`Word.xpos`:\", a_word_concurrunt.xpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the whole book of Genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = {}\n",
    "\n",
    "for ve in vulgate_genesis:\n",
    "    gen_doc = cltk_nlp.analyze(text=vulgate_genesis[ve])\n",
    "    for wo in gen_doc:\n",
    "        word_dict = {}\n",
    "        word_dict['text'] = wo.string\n",
    "        word_dict['lemma'] = wo.lemma\n",
    "        word_dict['pos'] = wo.pos\n",
    "        features = wo.features\n",
    "            \n",
    "        print(word_dict)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling syntax with `Form` and `DependencyTree`  <a name=\"syntax\"></a>\n",
    "\n",
    "The CLTK uses the builtin `xml` library to build tree for modeling dependency parses. A `Word` is mapped into a `Form`, then `ElemntTree` is used to organize these `Form`s into a `DependencyTree`. With a tree, certain measurements are more efficient (counting depth, breadth, edge types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.dependency.tree import DependencyTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at this sentence again\n",
    "print(cltk_doc.sentences_strings[6])  # text form of `sentence_6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tree = DependencyTree.to_tree(sentence_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(a_tree.get_dependencies())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tree.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction <a name=\"features\"></a>\n",
    "\n",
    "The CLTK offers the function `cltk_doc_to_features_table()`, which assist users when preparing a `Doc` for training data for machine learning. It converts the list of `Word` objects at `Doc.words` into a tabular list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.utils.feature_extraction import cltk_doc_to_features_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names, list_of_list_features = cltk_doc_to_features_table(cltk_doc=cltk_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See here the names of the features extracted\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of \"inner lists\" matches number of tokens\n",
    "print(\"Number tokens:\", len(cltk_doc.words))\n",
    "print(\"len() of feature instances (one for each token):\", len(list_of_list_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at one row of data `(variable name, variable value)`\n",
    "pprint(list(zip(feature_names, list_of_list_features[108])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief demonstration of `NLP()` for Ancient Greek <a name=\"greek-nlp\"></a>\n",
    "\n",
    "The API for Greek is the same as Latin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Ancient Greek file\n",
    "with open(\"grc-thucydides.txt\") as fo:\n",
    "    thucydides_full = fo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Text snippet:\", thucydides_full[0:200])\n",
    "print(\"Character count:\", len(thucydides_full))\n",
    "print(\"Approximate token count:\", len(thucydides_full.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(thucydides_full) // 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut this down to roughly 10k tokens for this demonstration's purposes\n",
    "thucydides = thucydides_full[:len(thucydides_full) // 7]\n",
    "print(\"Approximate token count:\", len(thucydides.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thucydides[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cltk_nlp_grc = NLP(language=\"grc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution time is 50 sec on a 2015 Macbook Pro\n",
    "%time cltk_doc_grc = cltk_nlp_grc.analyze(text=thucydides)\n",
    "\n",
    "# You will be asked to download some models (from CLTK, fastText, and Stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"`Doc.tokens`:\", cltk_doc_grc.tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc_grc.words[4])  # πόλεμον ('war')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tree_grc = DependencyTree.to_tree(cltk_doc_grc.sentences[0])  #81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(a_tree_grc.get_dependencies())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc_grc.sentences_strings[0])\n",
    "print(\"\")\n",
    "print(\"Translation:\", \"Thucydides, an Athenian, wrote the history of the war between the Peloponnesians and the Athenians, beginning at the moment that it broke out, and believing that it would be a great war, and more worthy of relation than any that had preceded it. This belief was not without its grounds. The preparations of both the combatants were in every department in the last state of perfection; and he could see the rest of the Hellenic race taking sides in the quarrel; those who delayed doing so at once having it in contemplation.\")\n",
    "print(\"\")\n",
    "a_tree_grc.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_grc, list_of_list_features_grc = cltk_doc_to_features_table(cltk_doc=cltk_doc_grc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_names_grc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len() of feature instances (one for each token):\", len(list_of_list_features_grc))\n",
    "print(\"\")\n",
    "print(\"Example of one instance row:\", list_of_list_features_grc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting these together for easier reading\n",
    "pprint(list(zip(feature_names_grc, list_of_list_features_grc[4])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
