{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Introduction](#introduction)\n",
    "1. [Install pre-release of CLTK](#install)\n",
    "1. [Load data](#load)\n",
    "1. [Run NLP pipeline with `NLP()`](#run-nlp)\n",
    "1. [Inspect CLTK `Doc`](#inspect-doc)\n",
    "1. [Inspect CLTK `Word`](#inspect-word)\n",
    "1. [Analyze the whole book of Genesis](#analyze-book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "This notebook is based on [a notebook](https://github.com/cltk/cltk/blob/master/notebooks/CLTK%20Demonstration.ipynb) from the [Classical Language Toolkit project](http://cltk.org). We will annotate the text of the Vulgate of Genesis, using the pipeline that is provided for the Latin language. We use the text of the Latin Genesis as it is provided [here](https://github.com/cltk/lat_text_tesserae).\n",
    "\n",
    "This notebook demonstrates how to use `NLP()`, the CLTK's primary interface, in Latin and Ancient Greek. Pipelines are available for 17 languages (see [Languages](https://docs.cltk.org/en/latest/languages.html) in the docs).\n",
    "\n",
    "Full documentation available at <https://docs.cltk.org/en/latest/cltk.html#cltk.nlp.NLP>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install CLTK <a name=\"install\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requires Python 3.7, 3.8, or 3.9\n",
    "\n",
    "# !pip install cltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data <a name=\"load\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the text of Genesis, read it line by line, parse the label (book, chapter, verse), and store the data in the dictionary vulgate_genesis. In this dict, the keys are a tuple containing book, chapter and verse, and the values consist of a string, containing the text of a verse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vulgate_genesis = {}\n",
    "\n",
    "with open(\"jerome.vulgate.part.1.genesis.tess\") as gen:\n",
    "    for line in gen:\n",
    "\n",
    "        label, text = line.split('> ')\n",
    "        _, bo_ch_ve = label.split()\n",
    "        bo, ch, ve = bo_ch_ve.split('.')\n",
    "        vulgate_genesis[(bo, ch, ve)] = text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many verses are there in Genesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vulgate_genesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the text of Genesis 10:10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vulgate_genesis[('Genesis', '10', '10')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run NLP pipeline with `NLP()` <a name=\"run-nlp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk import NLP\n",
    "from cltk.morphology.utils import get_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cltk_nlp = NLP(language=\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing ``LatinLexiconProcess`` for this demo b/c it is slow (adds ~9 mins total)\n",
    "cltk_nlp.pipeline.processes.pop(-1)\n",
    "print(cltk_nlp.pipeline.processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the pipeline does with Genesis 1:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cltk_doc = cltk_nlp.analyze(text=vulgate_genesis[('Genesis', '1', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect CLTK `Doc` <a name=\"inspect-doc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline has created a Doc object of our string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(cltk_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we access this Doc object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(cltk_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the tokens! Note that the semicolon at the end is parsed as a separate token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc.lemmata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentences_tokens is a list of lists, which contains the sentences in the string under consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cltk_doc.sentences_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect CLTK `Word` <a name=\"inspect-word\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most powerful, though, is the ``Doc.words`` accessor, which is a list of ``Word`` objects. These ``Word`` objects contain all information that was generated during the NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Word object for each token\n",
    "print(len(cltk_doc.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wo in cltk_doc.words:\n",
    "    print(wo.lemma, wo.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the verb of the sentence, to be able to inspect its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cltk_doc.words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creavit = cltk_doc.words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creavit.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the other word features with the function get_features()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features(creavit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that this function returns a tuple, which contains 2 lists. One list contains the feature names, the other contains the values. We can unpack the tuple by assigning each list to a variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names, feature_values = get_features(creavit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the whole book of Genesis <a name=\"analyze-book\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = set()\n",
    "all_words_genesis = {}\n",
    "\n",
    "for verse in vulgate_genesis:\n",
    "    bo, ch, ve = verse\n",
    "    gen_doc = cltk_nlp.analyze(text=vulgate_genesis[verse])\n",
    "    for idx, wo in enumerate(gen_doc):\n",
    "\n",
    "        word_string = wo.string\n",
    "        word_lemma = wo.lemma\n",
    "        word_pos = wo.pos\n",
    "        \n",
    "        feature_names, feature_values = get_features(wo)\n",
    "        all_features.add(tuple(feature_names))\n",
    "            \n",
    "        feature_list = [bo, ch, ve, word_string, word_lemma, word_pos]\n",
    "        for feature in feature_values:\n",
    "            if not feature:\n",
    "                feature_list.append('-')\n",
    "            else:\n",
    "                feature_list.append(feature)\n",
    "        all_words_genesis[(idx, bo, ch, ve)] = feature_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genesis = pd.DataFrame(all_words_genesis).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genesis_colnames = ['book', \n",
    "                    'chapter',\n",
    "                    'verse', \n",
    "                    'text', \n",
    "                    'lemma', \n",
    "                    'pos', \n",
    "                    'case',\n",
    "                    'gender',\n",
    "                    'animacy',\n",
    "                    'number',\n",
    "                    'definiteness',\n",
    "                    'degree',\n",
    "                    'strength',\n",
    "                    'verbform',\n",
    "                    'tense',\n",
    "                    'mood',\n",
    "                    'aspect',\n",
    "                    'voice',\n",
    "                    'person',\n",
    "                    'polarity',\n",
    "                    'politeness',\n",
    "                    'clusivity',\n",
    "                    'evidentiality',\n",
    "                    'strength']\n",
    "\n",
    "genesis.columns = genesis_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genesis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genesis.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the result as a tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genesis.to_csv('genesis.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
